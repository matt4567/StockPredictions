{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named helper",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fea340810da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named helper"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense, Activation, Dropout\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "import handler\n",
    "\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers.recurrent import LSTM\n",
    "import time, helper\n",
    "print 'complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_data(stock_name):\n",
    "    url=\"http://www.google.com/finance/historical?q=\"+stock_name+\"&startdate=Jul+12%2C+2010&num=30&ei=rCtlWZGSFN3KsQHwrqWQCw&output=csv\"\n",
    "\n",
    "    df = pd.DataFrame.from_csv(url)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'GOOGL'\n",
    "df = get_stock_data(stock_name)\n",
    "df = df.iloc[::-1]\n",
    "print df.head()\n",
    "stockArray = df.as_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data into training, testing and validation data\n",
    "x_open_train, y_open_train, x_open_valid, y_open_valid, x_open_test, y_open_test = handler.handleData(stockArray[:,0], 50, True, False)\n",
    "x_high_train, y_high_train, x_high_valid, y_high_valid, x_high_test, y_high_test = handler.handleData(stockArray[:,1], 50, True, False)\n",
    "x_low_train, y_low_train, x_low_valid, y_low_valid, x_low_test, y_low_test = handler.handleData(stockArray[:,2], 50, True,False)\n",
    "x_vol_train, y_vol_train, x_vol_valid, y_vol_valid, x_vol_test, y_vol_test = handler.handleData(stockArray[:,4], 50, True,False)\n",
    "x_orig_test, norms, x_close_train, y_close_train, x_close_valid, y_close_valid, x_close_test, y_close_test = handler.handleData(stockArray[:,3], 50, True,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "d = 0.4\n",
    "\n",
    "\n",
    "# First Input\n",
    "main_input = Input(shape=(None, 1), dtype='float32', name='main_input')\n",
    "x = LSTM(input_dim = 1,\n",
    "               output_dim = 100,\n",
    "               return_sequences = True)(main_input)\n",
    "x = Dropout(d)(x)\n",
    "x = LSTM(128, return_sequences = False)(x)\n",
    "x = Dropout(d)(x)\n",
    "\n",
    "\n",
    "\n",
    "# Second Input\n",
    "aux_input = Input(shape=(None, 1), dtype=\"float32\", name =\"aux_input\")\n",
    "y = LSTM(input_dim = 1,\n",
    "               output_dim = 50,\n",
    "               return_sequences = True)(main_input)\n",
    "y = Dropout(d)(y)\n",
    "y = LSTM(100, return_sequences = False)(y)\n",
    "y = Dropout(0.8)(y)\n",
    "\n",
    "\n",
    "\n",
    "# Third Input\n",
    "tert_input = Input(shape=(None, 1), dtype=\"float32\", name =\"tert_input\")\n",
    "a = LSTM(input_dim = 1,\n",
    "               output_dim = 50,\n",
    "               return_sequences = True)(main_input)\n",
    "a = Dropout(d)(a)\n",
    "a = LSTM(100, return_sequences = False)(a)\n",
    "a = Dropout(0.8)(a)\n",
    "\n",
    "\n",
    "\n",
    "# Concatination of inputs\n",
    "z = keras.layers.concatenate([x, y])\n",
    "\n",
    "\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(d)(x)\n",
    "x = Dense(128,activation=\"relu\" )(x)\n",
    "x = Dropout(d)(x)\n",
    "x = Dense(128, activation ='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "\n",
    "main_output = Dense(1, activation=\"tanh\", name =\"main_output\")(x)\n",
    "\n",
    "start = time.time()\n",
    "model = Model(inputs=[main_input, aux_input, tert_input], outputs=[main_output])\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print 'compilation time : ', time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x_close_train, x_open_train, x_high_train], [y_close_train],\n",
    "          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find accuracy of and plot validation data\n",
    "\n",
    "p = model.predict([x_close_valid, x_open_valid, x_high_valid])\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "for i, item in enumerate(p):\n",
    "    if i >0:\n",
    "        pred = p[i] - x_close_valid[i, -1]\n",
    "        truth = y_close_valid[i] - x_close_valid[i,-1]\n",
    "        \n",
    "        if pred/truth > 0:\n",
    "            \n",
    "            correct = correct + 1\n",
    "            \n",
    "        else:\n",
    "            incorrect = incorrect + 1\n",
    "\n",
    "prop = correct / (correct + incorrect)\n",
    "print \"Proportion correct is: \", prop\n",
    "\n",
    "plt.title(\"Validation Data Plot\")\n",
    "plt.plot(p, label = \"Predictions\")\n",
    "plt.plot(y_close_valid, label = \"Actual results\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict([x_close_test, x_open_test, x_high_test])\n",
    "\n",
    "p_denorm = handler.denormalise_sequence(p, norms)\n",
    "\n",
    "# Plot to normalised predictions\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Normalised predictions plot\")\n",
    "plt.plot(p, color = \"green\", label = \"Predictions\")\n",
    "plt.plot(y_close_test, color = \"yellow\", label=\"Actual Data\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "\n",
    "y_denorm = handler.denormalise_sequence(y_close_test, norms)\n",
    "\n",
    "# Find accuracy of denormalised predictions\n",
    "for i, item in enumerate(p_denorm):\n",
    "    if i >0:\n",
    "        pred = p_denorm[i] - y_denorm[i-1]\n",
    "        truth = y_denorm[i] - y_denorm[i-1]\n",
    "        \n",
    "        if pred/truth > 0:\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            incorrect = incorrect + 1\n",
    "\n",
    "propDenorm = correct / (correct + incorrect)\n",
    "print \"Proportion correct is: \", prop\n",
    "\n",
    "# Check above prediction on normalised predictions\n",
    "for i, item in enumerate(p):\n",
    "    if i > 0:\n",
    "        pred = p[i] - x_close_test[i,-1]\n",
    "        truth = y_close_test[i] - x_close_test[i,-1]\n",
    "        \n",
    "        if pred/truth > 0:\n",
    "            \n",
    "            correct = correct + 1\n",
    "            \n",
    "        else:\n",
    "            incorrect = incorrect + 1\n",
    "\n",
    "propNorm = correct / (correct + incorrect)\n",
    "print \"Proportion correct is: \", prop\n",
    "\n",
    "if propDenorm == propNorm:\n",
    "    print \"Predictions match!\"\n",
    "    \n",
    "else:\n",
    "    print \"Predictions do not match!\"\n",
    "\n",
    "# Plot denormalised predictions\n",
    "plt.subplot(212)\n",
    "plt.title(\"Denormalised predictictions plot\")\n",
    "plt.plot(p_denorm, color = \"red\", label = \"Predictions\")\n",
    "plt.plot(y_denorm ,color='blue', label='Actual Data')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
